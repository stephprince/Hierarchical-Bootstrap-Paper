{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an adaptation of the hierarchical bootstrap simulation code from https://github.com/soberlab/Hierarchical-Bootstrap-Paper to use to compare ripple abundance between 5XFAD and WT mice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original simulation code worked over 2 levels of data - neurons and trials. This data was stored in a 2D array where rows = higher level (neurons) and columns = repetitions w/in that level (trials). Eventually 2 populations of neurons are compared with each other. \n",
    "\n",
    "### original simulation dataset\n",
    "  \n",
    "#### hierarchy of the data\n",
    "\n",
    "* neuron 1\n",
    "    * trial 1\n",
    "    * trial 2\n",
    "    * trial n\n",
    "* neuron 2\n",
    "    * trial 1\n",
    "    * trial 2\n",
    "    * trial n\n",
    "* neuron n\n",
    "    * trial 1\n",
    "    * trial 2\n",
    "    * trial n\n",
    "\n",
    "#### structure of the data\n",
    "\n",
    "    [neuron 1 trial 1, neuron 1 trial 2, neuron 1 trial N;\n",
    "     neuron 2 trial 1, neuron 2 trial 2, neuron 2 trial N;\n",
    "     neuron N trial 1, neuron N trial 2, neuron N trial N]\n",
    "\n",
    "The adapted bootstrapping code must work over 3 levels of data - animals, sessions, and time periods. There are not an equal number of repetitions across any of the levels, so this data is stored in the long data format. That is, a matrix where each row is a single time period, with the animal and session specified. Eventually 2 populations of animals from different genotypes are compared with each other.\n",
    "\n",
    "### my adapted dataset\n",
    "\n",
    "#### hierarchy of the data\n",
    "\n",
    "* genotype 1\n",
    "    * animal 1\n",
    "        * session 1\n",
    "            * period 1\n",
    "            * period n\n",
    "        * session 2\n",
    "            * period 1\n",
    "            * period n\n",
    "    * animal n\n",
    "        * session 1\n",
    "            * period 1\n",
    "            * period n\n",
    "        * session 2\n",
    "            * period 1\n",
    "            * period n\n",
    "* genotype 2\n",
    "    * animal 1\n",
    "        * session 1\n",
    "            * period 1\n",
    "            * period n\n",
    "        * session 2\n",
    "            * period 1\n",
    "            * period n\n",
    "    * animal n\n",
    "        * session 1\n",
    "            * period 1\n",
    "            * period n\n",
    "        * session 2\n",
    "            * period 1\n",
    "            * period n\n",
    "            \n",
    "#### structure of the data\n",
    "\n",
    "    [timeperiod 1, session 1, animal1;\n",
    "     timeperiod 2, session 1, animal1;\n",
    "     timeperiod N, session 1, animal1;\n",
    "     timeperiod 1, session N, animal1;\n",
    "     timeperiod N, session N, animal1;\n",
    "     timeperiod 1, session 1, animalN;\n",
    "     timeperiod N, session N, animalN]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions for bootstrap analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import the relevant libraries that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three functions are defined below: \n",
    "   * _get_bootstrapped_sample_ : a bootstrapping function over that runs nboot times through all levels of a hierarchical dataset.\n",
    "   * _bootstrap_rec_ : a recursive resampling function that resamples with replacement across all levels of the data.\n",
    "   * _get_direct_prob_ : A probablity function that can compute the pboot value between two populations of bootstrapped samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrapped_sample(variable,levels,nboot=1000):\n",
    "    '''\n",
    "    This function performs a hierarchical bootstrap on the data present in 'variable'.\n",
    "    This function assumes that the data in 'variable' is in the format of a dataframe where the\n",
    "    input 'levels' indicates which columns contain the data from highest hierarchical level to the lowest.\n",
    "    '''\n",
    "    bootstats = np.zeros(nboot)\n",
    "\n",
    "    #resample with replacement through all of the levels of the data\n",
    "    for i in np.arange(nboot):\n",
    "        temp = [];\n",
    "        rand_lev = np.unique(variable[levels[0]])\n",
    "        output = bootstrap_rec(variable,rand_lev,levels,temp) #recursive fxn to go through all hierarchical levels\n",
    "\n",
    "        #calculate the computation of interest (mean ripple rate in our case) here \n",
    "        bootstats[i] = np.nanmean(temp)\n",
    "\n",
    "    return bootstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_rec(data_input,rand_lev,levels,temp,n=0):\n",
    "    \n",
    "    if n == np.shape(levels)[0]-1:                                         #base condition - the lowest level\n",
    "        temp.extend(rand_lev)                                              #append data at lowest level\n",
    "        return temp\n",
    "    else:\n",
    "        for i in rand_lev:\n",
    "            #get random sampling of data\n",
    "            data_temp = data_input[data_input[levels[n]] == i]             #select subset of rows for first level\n",
    "            data_subset = np.unique(data_temp[levels[n+1]])                #select column with info for next level\n",
    "            num_subvals = np.shape(data_subset)[0]                         #get number of values within next level\n",
    "            rand_lev_new = np.random.choice(data_subset,int(num_subvals))  #random sample next level w/replacement\n",
    "            \n",
    "#             print('----------------------------------------------------------------- \\n'\n",
    "#                  'There are', num_subvals, levels[n+1], 'values for', levels[n], i, '\\n'\n",
    "#                  'The random samples with replacement are ', rand_lev_new)\n",
    "\n",
    "            bootstrap_rec(data_input,rand_lev_new,levels,temp,n+1)         #perform bootstrap at next level\n",
    "        n = n+1                                                            #adjust counter for current level\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direct_prob(sample1, sample2):\n",
    "    '''\n",
    "    get_direct_prob Returns the direct probability of items from sample2 being\n",
    "    greater than or equal to those from sample1.\n",
    "       Sample1 and Sample2 are two bootstrapped samples and this function\n",
    "       directly computes the probability of items from sample 2 being greater\n",
    "       than or equal to those from sample1. Since the bootstrapped samples are\n",
    "       themselves posterior distributions, this is a way of computing a\n",
    "       Bayesian probability. The joint matrix can also be returned to compute\n",
    "       directly upon.\n",
    "    '''\n",
    "    joint_low_val = min([min(sample1),min(sample2)])\n",
    "    joint_high_val = max([max(sample1),max(sample2)])\n",
    "    \n",
    "    p_joint_matrix = np.zeros((100,100))\n",
    "    p_axis = np.linspace(joint_low_val,joint_high_val,num=100)\n",
    "    edge_shift = (p_axis[2] - p_axis[1])/2\n",
    "    p_axis_edges = p_axis - edge_shift\n",
    "    p_axis_edges = np.append(p_axis_edges, (joint_high_val + edge_shift))\n",
    "\n",
    "    #Calculate probabilities using histcounts for edges.\n",
    "\n",
    "    p_sample1 = np.histogram(sample1,bins=p_axis_edges)[0]/np.size(sample1)\n",
    "    p_sample2 = np.histogram(sample2,bins=p_axis_edges)[0]/np.size(sample2)\n",
    "\n",
    "    #Now, calculate the joint probability matrix:\n",
    "\n",
    "    for i in np.arange(np.shape(p_joint_matrix)[0]):\n",
    "        for j in np.arange(np.shape(p_joint_matrix)[1]):\n",
    "            p_joint_matrix[i,j] = p_sample1[i]*p_sample2[j]\n",
    "            \n",
    "    #Normalize the joint probability matrix:\n",
    "    p_joint_matrix = p_joint_matrix/np.sum(p_joint_matrix)\n",
    "    \n",
    "    #Get the volume of the joint probability matrix in the upper triangle:\n",
    "    p_test = np.sum(np.triu(p_joint_matrix))\n",
    "    \n",
    "    return p_test, p_joint_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Loading and splitting up the data by genotype\n",
    "\n",
    "We want to compare all of the time periods recorded from X number of sessions from 9 animals in the two different 5XFAD and WT groups. First we will clean the data by splitting it up into the 5XFAD and WT groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load in the data frame. Then select the 5XFAD and WT subsets of the original data frame based on their genotype ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>riprates</th>\n",
       "      <th>genotypeID</th>\n",
       "      <th>anID</th>\n",
       "      <th>sessID</th>\n",
       "      <th>periodID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   riprates  genotypeID  anID  sessID  periodID\n",
       "0       0.0           2     8       1         1\n",
       "1       0.0           2     8       1         2\n",
       "2       0.0           2     8       1         3\n",
       "3       0.0           2     8       1         4\n",
       "4       0.0           2     8       1         5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ripRateTable5to2000s.csv\")\n",
    "data_FAD = df[df.genotypeID == 1] #1 indicates FAD \n",
    "data_WT = df[df.genotypeID == 2] #2 indicates WT\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Calculating traditional statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the traditional statistics for the data using all of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional rank sum p-value: 1.917061145057577e-16\n"
     ]
    }
   ],
   "source": [
    "#Get ranksum p-value for traditional calculation:\n",
    "ranksum_results = stats.ranksums(data_FAD.riprates,data_WT.riprates)[1]\n",
    "\n",
    "#Get SEMs for the same:\n",
    "ranksum_sem_FAD = np.std(data_FAD.riprates)/np.sqrt(np.size(data_FAD.riprates))\n",
    "ranksum_sem_WT = np.std(data_WT.riprates)/np.sqrt(np.size(data_WT.riprates))\n",
    "ranksum_mean_FAD = np.nanmean(data_FAD.riprates)\n",
    "ranksum_mean_WT = np.nanmean(data_WT.riprates)\n",
    "\n",
    "print(\"Traditional rank sum p-value:\", ranksum_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Calculating summarized statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the summarized statistics for the data by getting an average ripple rate for each animal across all sessions and time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5XFAD means are [0.00516463 0.00104937 0.00650678 0.04743681 0.03454172] \n",
      "WT means are [0.14861612 0.01472387 0.12741749 0.03519837]\n",
      "Summarized statistics rank sum p-value: 0.0864107329737\n"
     ]
    }
   ],
   "source": [
    "#Get the summarized values for each animal for each genotype:\n",
    "iden_an_FAD = np.unique(data_FAD.anID)\n",
    "mean_an_FAD = [] #initialize data struct\n",
    "for i in iden_an_FAD:\n",
    "    an_data = data_FAD[data_FAD.anID == i]\n",
    "    an_mean = np.nanmean(an_data.riprates) #get average ripple rate for each animal across sessions/timeperiods\n",
    "    mean_an_FAD = np.append(mean_an_FAD, an_mean)\n",
    "    \n",
    "iden_an_WT = np.unique(data_WT.anID)\n",
    "mean_an_WT = [] #initialize data struct\n",
    "for i in iden_an_WT:\n",
    "    an_data = data_WT[data_WT.anID == i]\n",
    "    an_mean = np.nanmean(an_data.riprates) #get average ripple rate for each animal across sessions/timeperiods\n",
    "    mean_an_WT = np.append(mean_an_WT, an_mean)\n",
    "    \n",
    "#Get ranksum p-value for summarized calculation:\n",
    "ranksum_sum_results = stats.ranksums(mean_an_FAD,mean_an_WT)[1]\n",
    "#Get SEMs for the same:\n",
    "ranksum_sum_sem_FAD = np.std(mean_an_FAD)/np.sqrt(np.size(mean_an_FAD))\n",
    "ranksum_sum_sem_WT = np.std(mean_an_WT)/np.sqrt(np.size(mean_an_WT))\n",
    "ranksum_sum_mean_FAD = np.nanmean(mean_an_FAD)\n",
    "ranksum_sum_mean_WT = np.nanmean(mean_an_WT)\n",
    "\n",
    "print(\"5XFAD means are\", mean_an_FAD, \"\\nWT means are\", mean_an_WT)\n",
    "print(\"Summarized statistics rank sum p-value:\", ranksum_sum_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Calculating the bootstrap statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get the bootstrapped samples and probability for the hierarchical bootstrap statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 completed\n",
      "Run 1 completed\n",
      "Run 2 completed\n",
      "Run 3 completed\n",
      "Run 4 completed\n",
      "Run 5 completed\n",
      "Run 6 completed\n",
      "Run 7 completed\n",
      "Run 8 completed\n",
      "Run 9 completed\n"
     ]
    }
   ],
   "source": [
    "n_runs = 10\n",
    "bootstrap_results = np.zeros((n_runs,3))\n",
    "\n",
    "for i in np.arange(n_runs):\n",
    "    \n",
    "    #define the levels we will use (ordered from highest to lowest)\n",
    "    levels = ['anID','sessID','riprates'];\n",
    "    \n",
    "    #calculate bootstrapped samples:\n",
    "    bootstats_FAD = get_bootstrapped_sample(data_FAD, levels)\n",
    "    bootstats_WT = get_bootstrapped_sample(data_WT, levels)\n",
    "    \n",
    "    #Calculate probability of bootstats2 >= bootstats1:\n",
    "    bootstrap_results[i,0] = get_direct_prob(bootstats_FAD,bootstats_WT)[0]\n",
    "    \n",
    "    #Get SEM from bootstrapped samples:\n",
    "    bootstrap_results[i,1] = np.std(bootstats_FAD)\n",
    "    bootstrap_results[i,2] = np.std(bootstats_WT)\n",
    "    \n",
    "    print(\"Run {} completed\".format(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will concatenate the results across different statistical tests and bootstrap runs. We will save these results since this code can take a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate results across all runs\n",
    "results = np.zeros((n_runs,3))\n",
    "sem_results = np.zeros((n_runs,6))\n",
    "mean_results = np.zeros((n_runs,6))\n",
    "for i in np.arange(n_runs):\n",
    "    #fill in the output data structure with the results\n",
    "    results[i,0] = ranksum_results\n",
    "    results[i,1] = ranksum_sum_results\n",
    "    results[i,2] = bootstrap_results[i,1]\n",
    "    mean_results[i,0] = ranksum_mean_FAD\n",
    "    mean_results[i,1] = ranksum_mean_WT\n",
    "    mean_results[i,2] = ranksum_sum_mean_FAD\n",
    "    mean_results[i,3] = ranksum_sum_mean_WT\n",
    "    mean_results[i,4] = bootstrap_results[i,1]\n",
    "    mean_results[i,5] = bootstrap_results[i,2]\n",
    "    \n",
    "    sem_results[i,0] = ranksum_sem_FAD\n",
    "    sem_results[i,1] = ranksum_sem_WT\n",
    "    sem_results[i,2] = ranksum_sum_sem_FAD\n",
    "    sem_results[i,3] = ranksum_sum_sem_WT\n",
    "    sem_results[i,4] = bootstrap_results[i,1]\n",
    "    sem_results[i,5] = bootstrap_results[i,2]\n",
    "    \n",
    "#Get the proportion of significant differences:\n",
    "prop_of_sig_results = np.zeros(3)\n",
    "prop_of_sig_results[0] = np.sum(results[:,0]<0.05)/np.size(results[:,0]) #ranksum\n",
    "prop_of_sig_results[1] = np.sum(results[:,1]<0.05)/np.size(results[:,1]) #ranksum sum\n",
    "prop_of_sig_results[2] = np.sum((results[:,2]<0.05) | (results[:,2]>0.95))/np.size(results[:,0]) #bootstrap\n",
    "\n",
    "#Save the measures of the SEM:\n",
    "sem_summaries = np.zeros(6)\n",
    "sem_summaries[0] = np.mean(sem_results[:,:2])    # ranksum traditional stats\n",
    "sem_summaries[1] = np.std(sem_results[:,:2])\n",
    "sem_summaries[2] = np.mean(sem_results[:,2:4])   # ranksum summarized stats\n",
    "sem_summaries[3] = np.std(sem_results[:,2:4])\n",
    "sem_summaries[4] = np.mean(sem_results[:,4:])    # bootstrap\n",
    "sem_summaries[5] = np.std(sem_results[:,4:])\n",
    "\n",
    "#save the output to a text file\n",
    "np.savetxt('sig_results_riprates_5XADvsWT.csv',prop_of_sig_results,delimiter=',')\n",
    "np.savetxt('sem_summaries_riprates_5XADvsWT.csv',sem_summaries,delimiter=',')\n",
    "np.savetxt('pvalues_full_riprates_5XADvsWT.csv',results,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved values into the corresponding variable names:\n",
    "prop_of_sig_results = np.loadtxt('sig_results_riprates_5XADvsWT.csv',delimiter=',')\n",
    "sem_summaries = np.loadtxt('sem_summaries_riprates_5XADvsWT.csv',delimiter = ',')\n",
    "results = np.loadtxt('pvalues_full_riprates_5XADvsWT.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot the ripple abundance results between these two groups using the standard errors from the three statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['traditional (n = {})'.format(np.size(data_WT.riprates) + np.size(data_FAD.riprates)),\n",
    "          'summarized (n = {})'.format(np.size(mean_an_WT) + np.size(mean_an_FAD)),\n",
    "          'bootstrap (runs = {})'.format(n_runs)]\n",
    "xlabels = ['FAD', 'WT']\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "#plot data with means and sems for all statistical tests\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True)\n",
    "fig.text(0.05, 0.5, 'Ripple Abundance (Hz)', va='center',rotation=90)\n",
    "counter = 0\n",
    "for i in np.arange(0,6,2): #5XFAD are all the odds\n",
    "    axs[counter].errorbar(0, np.mean(mean_results[:,i]), yerr=sem_summaries[i], fmt='o', color='green', ecolor='lightgreen', elinewidth=3, capsize=0);\n",
    "    axs[counter].errorbar(1, np.mean(mean_results[:,i+1]), yerr=sem_summaries[i+1], fmt='o', color='black', ecolor='lightgray', elinewidth=3, capsize=0);\n",
    "    axs[counter].scatter('FAD', np.mean(mean_results[:,i]), color='green')\n",
    "    axs[counter].scatter('WT', np.mean(mean_results[:,i+1]), color='black')\n",
    "    axs[counter].set_title(labels[counter])\n",
    "    axs[counter].set_ylim(-0.025,0.1)\n",
    "    axs[counter].set_xlim(-0.5,1.5)\n",
    "    counter += 1\n",
    "    \n",
    "#plot proportion of significant results for all statistical tests\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True)\n",
    "fig.text(0.05, 0.5, 'Proportion of significant results', va='center',rotation=90)\n",
    "counter = 0\n",
    "for i in np.arange(0,3):\n",
    "    axs[counter].bar(0,prop_of_sig_results[i], color='blue')\n",
    "    axs[counter].set_title(labels[counter])\n",
    "    axs[counter].plot([-0.5, 0.5],[0.05, 0.05],color='k',dashes=[12,5],label = '5% level')\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
